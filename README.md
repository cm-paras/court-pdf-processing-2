# PDF Processing Pipeline - Modular Architecture

A professional, modular Python application for processing legal PDFs, extracting metadata, and indexing them in Azure Cognitive Search.

## ğŸ“ Project Structure

```
search-index-cloner/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ config.py              # Configuration management
â”‚   â”œâ”€â”€ clients/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ azure_clients.py       # Azure service clients
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pdf_downloader.py      # PDF download functionality
â”‚   â”‚   â”œâ”€â”€ text_extractor.py      # Text extraction from PDFs
â”‚   â”‚   â”œâ”€â”€ metadata_extractor.py  # AI-powered metadata extraction
â”‚   â”‚   â”œâ”€â”€ document_chunker.py    # Document chunking
â”‚   â”‚   â””â”€â”€ embedding_generator.py # Vector embedding generation
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cosmos_storage.py      # Cosmos DB operations
â”‚   â”‚   â””â”€â”€ search_indexer.py      # Azure Search indexing
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ pipeline.py            # Pipeline orchestration
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ logging_config.py      # Logging configuration
â”œâ”€â”€ main.py                         # Main entry point
â”œâ”€â”€ utils.py                        # Helper utilities
â”œâ”€â”€ .env                            # Environment variables
â”œâ”€â”€ url.pkl                         # PDF URLs
â””â”€â”€ README.md                       # This file
```

## ğŸŒŸ Features

- **Modular Architecture**: Clean separation of concerns with OOP design
- **Azure Integration**: Full integration with Azure Blob Storage, Cosmos DB, OpenAI, and Cognitive Search
- **Parallel Processing**: Multi-threaded processing at each stage
- **Batch Operations**: Efficient batch processing for large datasets
- **Error Handling**: Comprehensive error handling with retries
- **Progress Tracking**: Real-time progress indicators
- **Scalable**: Supports distributed processing across multiple servers

## ğŸš€ Quick Start

### Prerequisites

```bash
# Python 3.8+
python --version

# Install dependencies
pip install -r requirements.txt
```

### Environment Setup

Create a `.env` file with the following variables:

```env
# Azure Blob Storage
AZURE_STORAGE_CONNECTION_STRING=your_connection_string
BLOB_CONTAINER_NAME=your_container

# Azure Cosmos DB
COSMOS_DB_ENDPOINT=your_endpoint
COSMOS_DB_KEY=your_key
COSMOS_DB_DATABASE=your_database
COSMOS_DB_CONTAINER=your_container

# Azure OpenAI
AZURE_OPENAI_API_KEY=your_api_key
AZURE_OPENAI_ENDPOINT=your_endpoint
AZURE_OPENAI_CHAT_MODEL=gpt-4-mini

# Azure Cognitive Search
AZURE_SEARCH_ENDPOINT=your_search_endpoint
AZURE_SEARCH_KEY=your_search_key
AZURE_SEARCH_INDEX_NAME=your_index_name
```

### Basic Usage

```bash
# Process all PDFs
python main.py

# Process limited number of PDFs
python main.py --max_pdfs 100

# Skip to indexing (if PDFs already processed)
python main.py --skip_to_indexing

# Distributed processing (server 1 of 3)
python main.py -c 3 -s 0
```

## ğŸ“š Module Documentation

### Configuration (`src/config/`)
- **Config**: Centralized configuration with validation
- Environment variable management
- Processing parameters (batch sizes, workers, retries)

### Clients (`src/clients/`)
- **AzureClientManager**: Manages all Azure service clients
- HTTP session with retry logic
- Resource cleanup

### Processors (`src/processors/`)
- **PDFDownloader**: Downloads PDFs from Azure Blob or URLs
- **TextExtractor**: Extracts text using PyMuPDF
- **MetadataExtractor**: Extracts metadata using Azure OpenAI
- **DocumentChunker**: Splits documents into chunks
- **EmbeddingGenerator**: Generates vector embeddings

### Storage (`src/storage/`)
- **CosmosStorage**: Handles Cosmos DB operations
- **SearchIndexer**: Manages Azure Cognitive Search

### Pipeline (`src/pipeline/`)
- **PDFProcessingPipeline**: Orchestrates the entire workflow
- Batch processing with progress tracking
- Error handling and recovery

### Utils (`src/utils/`)
- **Logging**: Centralized logging configuration
- Suppresses verbose Azure SDK logs

## ğŸ”§ Command-Line Arguments

| Argument | Description | Default |
|----------|-------------|---------|
| `--max_pdfs` | Maximum number of PDFs to process | None (all) |
| `--skip_to_indexing` | Skip PDF processing, only index | False |
| `-c` | Total number of servers | 1 |
| `-s` | Current server number (0-indexed) | 0 |

## ğŸ—ï¸ Architecture Benefits

### 1. Modularity
- Each module has a single, well-defined responsibility
- Easy to understand, test, and maintain
- Components can be reused independently

### 2. Object-Oriented Design
- Classes encapsulate related functionality
- Clear interfaces between components
- Better code organization

### 3. Separation of Concerns
- Configuration separated from logic
- Logging centralized
- Azure clients managed separately

### 4. Maintainability
- Smaller files (50-200 lines each vs 2000+ lines)
- Clear naming conventions
- Comprehensive docstrings

### 5. Testability
- Each module can be unit tested
- Easy to mock dependencies
- Clear input/output contracts

## ğŸ“Š Performance

- **Parallel Processing**: Multi-threaded at each stage
- **Batch Operations**: Efficient batch processing
- **Connection Pooling**: Reuses HTTP connections
- **Retry Mechanisms**: Automatic retry with exponential backoff

## ğŸ”„ Pipeline Workflow

```
1. PDF Download
   â†“
2. Text Extraction
   â†“
3. Metadata Extraction (AI)
   â†“
4. Cosmos DB Storage
   â†“
5. Document Chunking
   â†“
6. Embedding Generation
   â†“
7. Search Index Upload
```

## ğŸ› ï¸ Development

### Adding New Features

1. Create a new module in the appropriate directory
2. Add a class with clear docstrings
3. Integrate with `pipeline.py`
4. Update this README

### Testing

```bash
# Test with a small batch
python main.py --max_pdfs 5
```

## ğŸ“ Dependencies

- `azure-storage-blob` - Azure Blob Storage
- `azure-cosmos` - Azure Cosmos DB
- `azure-search-documents` - Azure Cognitive Search
- `openai` - Azure OpenAI
- `pymupdf` (fitz) - PDF text extraction
- `langchain-text-splitters` - Document chunking
- `requests` - HTTP client
- `tqdm` - Progress bars
- `python-dotenv` - Environment variables

## ğŸ¤ Contributing

1. Follow the existing code structure
2. Add docstrings to all classes and methods
3. Keep modules focused and small
4. Update README for new features

## ğŸ“„ License

Same as the original project.

## ğŸ†š Migration from Original

The original monolithic `main.py` (2000+ lines) has been refactored into this modular structure:

- **Before**: One large file
- **After**: 12 focused modules in organized directories
- **Compatibility**: Same functionality, same CLI arguments
- **Benefits**: Better maintainability, testability, and reusability

## ğŸ› Troubleshooting

### Import Errors
Ensure you're running from the project root directory.

### Azure Connection Issues
Verify your `.env` file has all required variables.

### Memory Issues
Adjust batch sizes in `src/config/config.py`.

## ğŸ“ Support

For issues or questions, please refer to the project repository.

---

**Version**: 2.0.0  
**Last Updated**: December 2025
